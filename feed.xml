<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://manuelsh.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://manuelsh.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-03T10:54:33+00:00</updated><id>https://manuelsh.github.io/feed.xml</id><title type="html">Manuel Sánchez Hernández</title><subtitle>I like to do machine learning at scale </subtitle><entry><title type="html">LLMs from the Context Window Point of View</title><link href="https://manuelsh.github.io/blog/2025/understanding-LLM-from-context-window-pov/" rel="alternate" type="text/html" title="LLMs from the Context Window Point of View"/><published>2025-07-01T09:00:00+00:00</published><updated>2025-07-01T09:00:00+00:00</updated><id>https://manuelsh.github.io/blog/2025/understanding-LLM-from-context-window-pov</id><content type="html" xml:base="https://manuelsh.github.io/blog/2025/understanding-LLM-from-context-window-pov/"><![CDATA[<p><span style="color: grey; font-weight: 300; font-size: 0.9em;">3rd July 2025</span></p> <blockquote> <p>This article expands on ideas I first presented during a keynote at an AI Hackathon organized by <a href="https://www.fotocasa.es/en">Fotocasa</a>. I am grateful to the organizers for inviting me.</p> </blockquote> <p>Large Language Models don’t work the way most people think they do. They are massive neural networks with billions of parameters (neuronal connections), but when they’re generating responses (making an <em>inference</em>), they remain static: their internal state doesn’t change.</p> <p>The goal of this article is to demystify some of the inner workings of Large Language Models and explain how agentic behavior can be achieved. All from the perspective of the model’s input, which makes it very intuitive.</p> <h2 id="but-what-is-a-large-language-model">But what is a Large Language Model?</h2> <p>You might not realize it, but your phone has had a language model for over 10 years. Not a large one, but it’s there. It’s used to predict the next word you’ll type.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/mobile-keyboard-480.webp 480w,/assets/img/blog_images/mobile-keyboard-800.webp 800w,/assets/img/blog_images/mobile-keyboard-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/mobile-keyboard.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The keyboard of phone devices have had language models for over 10 years. </div> <p>Language models do exactly that: from a limited vocabulary —usually tens of thousands of the most common words— they choose the most likely next word given the previous context. They accomplish this based on the vast amounts of data they were trained on.</p> <p>Something fascinating happens when you scale up these models. By increasing both the number of parameters and the training data, the model suddenly becomes dramatically more powerful. Think of a parameter as a neural connection between two neurons —current largest models reach into the trillions of parameters (e.g., <a href="https://ai.meta.com/blog/llama-4-multimodal-intelligence/">Llama 4 Behemoth</a>).</p> <p>This performance change occurs almost like a phase transition: suddenly, when the model reaches a certain size and training duration (with sufficient data), it acquires entirely new abilities. This phenomenon was thoroughly documented in the paper <a href="https://arxiv.org/abs/2206.07682?utm_source=chatgpt.com">Emergent Abilities of Large Language Models</a>, and the scaling laws are also summarized in <a href="https://manuelsh.github.io/blog/2025/NIPS-building-llm-workshop/">Opening the LLM pipeline</a>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/emergent-abilities-llm-480.webp 480w,/assets/img/blog_images/emergent-abilities-llm-800.webp 800w,/assets/img/blog_images/emergent-abilities-llm-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/emergent-abilities-llm.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> After several computation cycles (flops) during the training of the model, they suddenly acquire new abilities, as measured in the different benchmarks. *Source: Emergent Abilities of Large Language Models, Oct 2022* </div> <p>In reality, LLMs don’t predict the next word —they predict the next token, which represents an optimal compromise between predicting individual characters and entire words. On average, a token corresponds to about 0.8 words. For simplicity, I’ll use “words” and “tokens” interchangeably throughout this article.</p> <p>The task of predicting the next word is surprisingly profound. Consider this prompt:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"The cat sat on the mat" in Spanish is
</code></pre></div></div> <p>To predict the next set of tokens, the model needs to understand how to translate from English to Spanish:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"El gato se sentó en la alfombra"
</code></pre></div></div> <p>Or consider this more complex example:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>You are a Grandmaster chess player. Predict the next move:
1. e4 c6 2. d4 d5 3. Nc3 dxe4 4. Nxe4 Nf6 5. Nxf6+ exf6 6. 
</code></pre></div></div> <p>Here, the model needs to understand chess strategy to suggest a good move.</p> <p>Therefore, predicting the next word requires learning to translate, play chess, write poetry, code, and much more. Essentially learning about the world itself. As Ilya Sutskever said, “text is just a projection of the world.”</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/new-abilities-llm-480.webp 480w,/assets/img/blog_images/new-abilities-llm-800.webp 800w,/assets/img/blog_images/new-abilities-llm-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/new-abilities-llm.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Predicting the next token implies learning about the world. </div> <h3 id="from-llm-to-chatbot">From LLM to Chatbot</h3> <p>While LLMs are powerful on their own, creating a chatbot like ChatGPT requires additional steps. Chatbots need to maintain coherent conversations, which demands more than just next-token prediction. This is where <em>reinforcement learning</em> comes into play. In simplified terms, the process to go from an LLM to a chatbot with certain characteristics looks like this:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/rlhf-simple-480.webp 480w,/assets/img/blog_images/rlhf-simple-800.webp 800w,/assets/img/blog_images/rlhf-simple-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/rlhf-simple.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Reinforcement learning with human feedback (RLHF)simplified. </div> <p>Starting with a raw LLM, we ask it to produce several answers to the same question. These answers are then rated by humans based on various criteria (usefulness, truthfulness, helpfulness, etc.). The ranked responses are used—through a process that may involve another model to retrain the LLM by readjusting its parameters. This process repeats iteratively until the model reaches a satisfactory state.</p> <h3 id="the-context-window">The Context Window</h3> <p>The context window represents the input to the LLM, essentially the set of tokens the model uses to predict the next one. Each LLM has a different context window size, as most architectures require quadratic scaling with size (though there are exceptions). The LLM with the largest context window (Llama 4 Scout) can process 10 million tokens, which is roughly equivalent to the first 5 volumes of the Encyclopedia Britannica.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/encyclopaedia-britannica-480.webp 480w,/assets/img/blog_images/encyclopaedia-britannica-800.webp 800w,/assets/img/blog_images/encyclopaedia-britannica-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/encyclopaedia-britannica.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The LLM with the largest context window (Llama 4 Scout) has 10 million tokens, which can process the first 5 volumes of the Encyclopedia Britannica (~7.6M words) in one go. </div> <p>Are models with larger context windows necessarily better? The trend over the past few years has been exponential growth, until recently. With the introduction of reasoning models in the last year, this trend has plateaued. This shift occurs partly because reasoning models iterate over input data in an “agentic mode”, working with summaries and strategically manipulating the context window to reach final answers. More on memory and agents later.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/context-window-length-480.webp 480w,/assets/img/blog_images/context-window-length-800.webp 800w,/assets/img/blog_images/context-window-length-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/context-window-length.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Context window length of prominent LLMs over time, logarithmic scale. They have been growing exponentially. </div> <h3 id="examples-of-calls-to-llms">Examples of Calls to LLMs</h3> <p>When we write somethingto an LLM, we’re actually sending a request to the trained neural network. This process of reading from the context window and generating predictions is called <em>inference</em>.</p> <p>What we write to the model is called a <em>prompt</em>, which gives rise to the term <em>prompt engineering</em>: the art of crafting prompts that produce desired outputs. As some have noted, a more accurate term would be <em>context engineering</em>.</p> <p>How does this work in practice? Let’s examine some examples. The call to the LLM is typically formatted as JSON, though what actually enters the context window is just a string. Here’s a simplified example of what this JSON looks like:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
  <span class="s">"messages"</span><span class="o">:</span> <span class="p">[</span>
    <span class="p">{</span> <span class="s">"role"</span><span class="o">:</span> <span class="s">"system"</span><span class="p">,</span>  <span class="s">"content"</span><span class="o">:</span> <span class="s">"You are a playful assistant."</span> <span class="p">},</span>
    <span class="p">{</span> <span class="s">"role"</span><span class="o">:</span> <span class="s">"user"</span><span class="p">,</span>    <span class="s">"content"</span><span class="o">:</span> <span class="s">"Hi!"</span> <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div> <p>The first message of the request above is the system message, which instructs the model on how to behave and can contain custom instructions. We’ll see more applications of this later.</p> <p>The second message is the user message: what the user has written. Together, these elements form the prompt. The model then generates a response. Technically, the model doesn’t produce a complete response at once, but generates one token at a time in a loop, reading the entire context window plus the newly generated token each time, until it produces a token that signals the end of the response. While this isn’t shown in the JSON format, it’s important to understand this mechanism.</p> <p>The response of the model can look like this:</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"messages"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"assistant"</span><span class="p">,</span><span class="w"> </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Hey there!"</span><span class="w"> </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>When the user asks another question, the entire conversation history is sent to the model again:</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"messages"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"system"</span><span class="p">,</span><span class="w">    </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"You are a playful assistant."</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"user"</span><span class="p">,</span><span class="w">      </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Hi!"</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"assistant"</span><span class="p">,</span><span class="w"> </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Hey there!"</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"user"</span><span class="p">,</span><span class="w">      </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Can you tell me a joke?"</span><span class="w"> </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>The model generates a response, and this process continues.</p> <p>As mentioned earlier, what actually enters the context window differs from the JSON format and looks like this in its raw form:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;|im_start|&gt;system
"You are a playful assistant.
&lt;|im_end|&gt;
&lt;|im_start|&gt;user
Hi!
&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
Hey there!
&lt;|im_end|&gt;
&lt;|im_start|&gt;user
Can you tell me a joke?
&lt;|im_end|&gt;

</code></pre></div></div> <p>where the <code class="language-plaintext highlighter-rouge">&lt;|im_start|&gt;</code> and <code class="language-plaintext highlighter-rouge">&lt;|im_end|&gt;</code> are actually tokens that mark the start and end of the message.</p> <h3 id="past-memories">Past memories</h3> <p>Many current LLM providers, such as OpenAI, have memories. So, if the neural network is static, how is this done?</p> <p>Again, through the context window. The model will store selected parts of the conversation (one can imagine an LLM runnning in the background that does that), and then adds them to the context window.</p> <p>The call to the model can look like this:</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"messages"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"system"</span><span class="p">,</span><span class="w">    </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"You are a playful assistant."</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"memory"</span><span class="p">,</span><span class="w">    </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"User name is Manuel."</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"memory"</span><span class="p">,</span><span class="w">    </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"User is from Spain."</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"user"</span><span class="p">,</span><span class="w">      </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Hi!"</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"assistant"</span><span class="p">,</span><span class="w"> </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Hey there!"</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"user"</span><span class="p">,</span><span class="w">      </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Can you tell me a joke?"</span><span class="w"> </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>where memories are incorporated as a special message type.</p> <h2 id="consciousness">Consciousness?</h2> <p>When using very powerful models that can engage in seemingly fluent conversations, it’s natural to believe the chatbot responds in an almost human-like way, as if it possesses some sort of consciousness. By examining the mechanics just explained, we can see that if any form of consciousness exists, it’s fundamentally different from human consciousness.</p> <p>First, the LLM’s neural network remains static: it doesn’t change. Therefore, there’s no evolution, no new memories are stored within it, and it doesn’t remember previous conversations or experiences. The model only responds to what’s in the current context window. It’s purely a function of its input: a function in the strict mathematical sense.</p> <p>Second, the neural network only activates during next-token prediction. If any form of consciousness exists within this network, it only lasts for the duration of this prediction process, with the context window’s content being a crucial component.</p> <p>I believe the next generation of AI should address this limitation: creating systems that evolve over time (with dynamic neural networks) and can independently store memories. This might involve incorporating retraining mechanisms, or even systems where new neurons are added and others removed.</p> <h2 id="agents">Agents</h2> <p>Agents do much more than simply respond to prompts. They can search the internet, call internal functions or external APIs, access past memories, etc. By examining the context window, we can understand how they work.</p> <p>Let’s consider a simple agent that can call a calculator function. Here’s how the conversation unfolds in the context window:</p> <p>First, the system message instructs the agent about its capabilities and how to use the calculator function. This is followed by the user’s question, which will trigger a multi-step process:</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"messages"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"system"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"You are an agent that can call a calculator function. The function `call_calculator` expects a JSON object with a single field `expression` containing a valid math expression and returns a JSON object with a field `result`."</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"user"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"What is 12 × 7?"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>The agent responds by indicating it needs to use the calculator:</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"assistant"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"I need to multiply two numbers. Action: call_calculator"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"function_call"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"call_calculator"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"arguments"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"expression"</span><span class="p">:</span><span class="w"> </span><span class="s2">"12 * 7"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>An external system parses this response, calls the calculator function, and adds the result back to the context:</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"function"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"call_calculator"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"{</span><span class="se">\"</span><span class="s2">result</span><span class="se">\"</span><span class="s2">: 84}"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>Finally, the LLM sees this result and provides the final answer:</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">
</span><span class="p">{</span><span class="w">
  </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"assistant"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Observation: The calculator says 84. Final Answer: 12 × 7 = 84."</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>The complete conversation in the context window looks like this:</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"messages"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"system"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"You are an agent that can call a calculator function. The function `call_calculator` expects a JSON object with a single field `expression` containing a valid math expression and returns a JSON object with a field `result`."</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"user"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"What is 12 × 7?"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"assistant"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"I need to multiply two numbers. Action: call_calculator"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"function_call"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"call_calculator"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"arguments"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nl">"expression"</span><span class="p">:</span><span class="w"> </span><span class="s2">"12 * 7"</span><span class="w">
        </span><span class="p">}</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"function"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"call_calculator"</span><span class="p">,</span><span class="w"> 
      </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"{</span><span class="se">\"</span><span class="s2">result</span><span class="se">\"</span><span class="s2">: 84}"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"assistant"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Observation: The calculator says 84. Final Answer: 12 × 7 = 84."</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>More complex agentic behaviors work similarly: function calls (internet searches, API calls, memory access) are all added to the context window, enabling the LLM to produce appropriate responses.</p> <p>Building agents involves more than just a context window and an LLM, you typically need a model-agnostic orchestrator (like <a href="https://www.langchain.com/">LangChain</a>) that manages <strong>state &amp; memory</strong> (buffers, summaries, vector stores), <strong>tool routing</strong> (function calls, search, code execution, APIs), <strong>multi-step planning with sub-agent spawning</strong>, and <strong>observability</strong> (tracing, cost tracking, evaluation pipelines); though this may feel overly complex for smaller projects.</p> <h2 id="the-journey-continues">The Journey Continues</h2> <p>In this post, we’ve explored several key concepts: the context window, tokens, prompt engineering, LLMs as mathematical functions, agentic behavior, and memory systems.</p> <p>This represents just a small portion of the broader LLM ecosystem. Many more concepts await exploration: embedding databases, RAG (Retrieval-Augmented Generation), reasoning models, MCPs (Model Context Protocol), and beyond. I encourage you to continue learning about these technologies and, most importantly, to start experimenting with them in your own projects.</p>]]></content><author><name></name></author><category term="machine"/><category term="learning,"/><category term="LLM,"/><category term="generative"/><category term="AI,"/><category term="context"/><category term="window"/><summary type="html"><![CDATA[The functioning of Large Language Models can be better understood from the perspective of their context window]]></summary></entry><entry><title type="html">Launching TheorIA: A Machine-Readable Atlas of Theoretical Physics</title><link href="https://manuelsh.github.io/blog/2025/launching-theoria-a-ML-dataset/" rel="alternate" type="text/html" title="Launching TheorIA: A Machine-Readable Atlas of Theoretical Physics"/><published>2025-05-25T09:00:00+00:00</published><updated>2025-05-25T09:00:00+00:00</updated><id>https://manuelsh.github.io/blog/2025/launching-theoria-a-ML-dataset</id><content type="html" xml:base="https://manuelsh.github.io/blog/2025/launching-theoria-a-ML-dataset/"><![CDATA[<p><span style="color: grey; font-weight: 300; font-size: 0.9em;">25th May 2025</span></p> <p>We are launching <a href="https://theoria-dataset.github.io/theoria-dataset/index.html">TheorIA Dataset</a> (Theoretical Physics Intelligent Anthology), a growing collection of physics equations, step-by-step derivations and plain-language explanations, fully written as self-contained JSON. It fills a gap identified in my earlier post <a href="https://manuelsh.github.io/blog/2025/datasets-for-advancing-Theoretical-Physics/">Datasets for advancing Theoretical Physics &amp; AI</a>, namely, the absence of curated, machine-readable data that goes beyond raw PDFs.</p> <p>We are trying to make something robust and with high-quality: built-in CI validation, explicit assumptions, programmatic proofs (SymPy), and arXiv-style domain tags to keep every entry reproducible and searchable.</p> <p>We currently have 15 entries, many written with AI, but some already curated by physicists, but we need hundreds. Your favourite derivation is probably still missing.</p> <p>All code and content is open source under the CC-BY 4.0 license on <a href="https://github.com/theoria-dataset/theoria-dataset">GitHub</a>. Pull requests are welcome!</p> <h2 id="why-bother">Why bother?</h2> <p>ImageNet rewired computer-vision research. In NLP, the Pile, C4 and friends did the same. Theoretical physics, on the other hand, still asks language models to learn Maxwell’s equations by going through paper PDFs.</p> <p>TheorIA is an attempt to raise the bar:</p> <table> <thead> <tr> <th>Pain point</th> <th>TheorIA’s answer</th> </tr> </thead> <tbody> <tr> <td>Equations are locked inside prose</td> <td>Each equation is a first-class JSON object, plus symbol table and AsciiMath rendering</td> </tr> <tr> <td>Derivations are opaque</td> <td>Straightforward step-by-step derivations with automated verification with SymPy</td> </tr> <tr> <td>Reproducibility headaches</td> <td>CI in Github validates all PRs against schema and proofs before merge</td> </tr> </tbody> </table> <h2 id="theoria-is-a-work-in-progress">TheorIA is a work in progress</h2> <p>Many of the entries you’ll find in TheorIA are currently in draft form, built with the help of AI tooling to bootstrap content at scale. Hence, they often contain typos, notation inconsistencies or even subtle mathematical errors. If they were perfect, this dataset would not be useful for training models.</p> <p>This is a feature, not a bug: by crowd-sourcing expert review and inviting physicists, mathematicians and educators to correct each derivation, we hope to rapidly turn these drafts into rock-solid reference materials. Your contributions will ensure that TheorIA remains both rigorous and reliable. We will very clearly mark the entries that are still not ready for use.</p> <h2 id="a-quick-tour">A quick tour</h2> <p>For now, we have built a simple <a href="https://theoria-dataset.github.io/theoria-dataset/index.html">web viewer to explore the dataset</a>, including each entry, which makes it easy to spot typos.</p> <p>The <a href="https://github.com/TheorIA-org/TheorIA">main repository</a> is on GitHub, and you can see an example of a raw entry here, the <a href="https://github.com/theoria-dataset/theoria-dataset/blob/main/entries/lorentz_transformations.json">Lorentz transformations</a>. We also have a comprehensive <a href="https://github.com/theoria-dataset/theoria-dataset/blob/main/CONTRIBUTING.md">contributing guide</a>.</p> <p>If you are not a software developer but you want to contribute by correcting or adding an entry, just follow the guidelines, create a json and add it as an <a href="https://github.com/theoria-dataset/theoria-dataset/issues">issue</a> in the repo. Remember to add your name or/and ORCID to the entry author field!</p> <h2 id="roadmap">Roadmap</h2> <p>The project is still early, and it requires significant work to make it useful and meaningful. You can follow the status in the <a href="https://github.com/users/theoria-dataset/projects/1/views/1">TheorIA project board</a>.</p> <p>The general steps we have in mind are:</p> <ol> <li>Build some critical mass: Have 100 AI generated entries (I expect them to have many errors, from the ones generated already) and at least 20 curaated by physicists.</li> <li>Test LLMs performance with the curated examples and compare their output.</li> <li>Reduce contributors friction: Have an easy way for users to modify or add entries to the dataset, from a user-friendly web interface.</li> <li>Automate output formats. Provide “one-click” scripts (JSON→LaTeX/Markdown/API) so adopters can plug TheorIA into documentation, teaching materials or model workflows without a learning curve.</li> <li>Once we have enough entries, deliver a demo. Fine-tune an LLM on the dataset and publicly compare its derivation-explanation quality against baselines.</li> </ol> <h2 id="call-for-collaborators">Call for collaborators</h2> <p>We’re especially looking for:</p> <ul> <li><strong>Physicists or students</strong> to review or add entries.</li> <li><strong>Toolsmiths</strong> to build visualisers, dataset converters or training scripts.</li> </ul> <h2 id="final-thoughts">Final thoughts</h2> <p>I hope that TheorIA will graduate from “neat GitHub repo” to a reference for physicists, educators and AI researchers. Join us in turning raw drafts into high-quality derivations, and let’s build the data foundation that physics and AI have been waiting for.</p>]]></content><author><name></name></author><category term="Machine"/><category term="Learning"/><summary type="html"><![CDATA[If we want AI models to reason about physics, we first need to give them physics they can actually read.]]></summary></entry><entry><title type="html">Datasets for advancing Theoretical Physics and AI</title><link href="https://manuelsh.github.io/blog/2025/datasets-for-advancing-Theoretical-Physics/" rel="alternate" type="text/html" title="Datasets for advancing Theoretical Physics and AI"/><published>2025-04-13T09:00:00+00:00</published><updated>2025-04-13T09:00:00+00:00</updated><id>https://manuelsh.github.io/blog/2025/datasets-for-advancing-Theoretical-Physics</id><content type="html" xml:base="https://manuelsh.github.io/blog/2025/datasets-for-advancing-Theoretical-Physics/"><![CDATA[<p><span style="color: grey; font-weight: 300; font-size: 0.9em;">13th April 2025</span></p> <p>The history of recent developments in deep learning shows the crucial role played by curated datasets. For example, Fei-Fei Li and her collaborators dramatically reshaped computer vision with the creation of <a href="https://arxiv.org/abs/1409.0575">ImageNet</a>, a large-scale, labeled image collection. This sparked the start of the deep learning revolution. Similarly, datasets like CIFAR-10 and MNIST have provided foundational benchmarks essential for algorithmic progress.</p> <p>Despite these advances in machine learning, theoretical physics still lacks comprehensive, standardized datasets. Developing high-quality datasets specifically tailored for theoretical physics could accelerate progress both in AI—by enabling more powerful models—and in physics itself, by establishing common benchmarks for training and evaluating physics-related models.</p> <p>In this post, I start by looking to the current existing physics related datasets by domain, data type, level of content and availability. Then I try to identify current existing gaps and propose new dataset creations.</p> <h2 id="existing-datasets">Existing Datasets</h2> <h3 id="theoretical-physics-knowledge--simulations">Theoretical Physics (Knowledge &amp; Simulations)</h3> <p>This includes textual corpora of theory papers, equation datasets, and simulation data of theoretical models.</p> <table> <thead> <tr> <th>Dataset / Source</th> <th>Domain &amp; Content</th> <th>Type</th> <th>Level</th> <th>Availability</th> </tr> </thead> <tbody> <tr> <td><strong>ArXiv Physics Corpus</strong></td> <td>All physics subfields (theory &amp; experiment) – 1.2M+ research papers (<a href="https://arxiv.org/html/2408.09574v1#:~:text=converts%20text%20into%20dense%20vector,tuning%20for%20specific%20physics%20subdomains">PhysBERT: A Text Embedding Model for Physics Scientific Literature</a>)</td> <td>Text (papers, PDFs)</td> <td>Frontier research</td> <td><a href="https://www.kaggle.com/datasets/Cornell-University/arxiv">Open-access</a> (arXiv)</td> </tr> <tr> <td><strong>Physics Journals (e.g. APS)</strong></td> <td>Broad physics research literature (peer-reviewed journals)</td> <td>Text (papers)</td> <td>Frontier research</td> <td>Restricted (subscription)</td> </tr> <tr> <td><strong>Feynman Symbolic Regression Dataset</strong></td> <td>Classical physics formulas (from Feynman Lectures, etc.) – 100+ laws</td> <td>Symbolic equations + numeric data</td> <td>Undergrad–Graduate</td> <td><a href="https://web.archive.org/web/20250319094015/https://space.mit.edu/home/tegmark/aifeynman.html">Open</a> (<a href="https://arxiv.org/pdf/1905.11481">research</a> dataset)</td> </tr> <tr> <td><strong>Kreuzer–Skarke Calabi–Yau DB</strong></td> <td>String theory – 473,800,776 reflexive 4D polytopes (Calabi–Yau manifolds) (<a href="https://pub.dzne.de/record/272345/files/DZNE-2024-01162.pdf">Group-invariant machine learning on the Kreuzer-Skarke dataset</a> - paywalled version: sciencedirect.com)</td> <td>Structured (geometric data)</td> <td>Frontier research</td> <td><a href="http://hep.itp.tuwien.ac.at/~kreuzer/CY/">Open</a> (online database)</td> </tr> <tr> <td><strong>Lattice QCD Configurations</strong></td> <td>Quantum Field Theory (lattice QCD) – gauge field samples, correlation functions</td> <td>Numeric (lattice data)</td> <td>Frontier research</td> <td>Partially open (<a href="https://www.jldg.org/ildg-data/">example</a>)</td> </tr> <tr> <td><strong>SXS Waveforms</strong> (Simulating eXtreme Spacetimes)</td> <td>General Relativity – Numerical relativity waveforms of binary black holes (<a href="https://data.black-holes.org/waveforms/index.html#:~:text=This%20repository%20contains%20all%20publicly,than%20Lev1%2C%20and%20so%20on">SXS Gravitational Waveform Database</a>)</td> <td>Numerical time-series</td> <td>Frontier research</td> <td><a href="https://data.black-holes.org/simulations/index.html">Open</a> (public catalog)</td> </tr> </tbody> </table> <h3 id="experimental-physics">Experimental Physics</h3> <p>Datasets from experiments and simulations that test physical theories, often used to train ML models to detect patterns or surrogate models for experiments.</p> <table> <thead> <tr> <th>Dataset / Source</th> <th>Domain &amp; Content</th> <th>Type</th> <th>Level</th> <th>Availability</th> </tr> </thead> <tbody> <tr> <td><strong>CERN Open Data (LHC)</strong></td> <td>High-energy physics – Petabytes of LHC collision data (ATLAS, CMS, etc.)</td> <td>Numerical (events, detector readings)</td> <td>Frontier research</td> <td><a href="https://opendata.cern.ch/#:~:text=Explore%20more%20than%20five%20petabytes,open%20data%20from%20particle%20physics">Open-access</a> (portal)</td> </tr> <tr> <td><strong>HEP ML Datasets</strong> (HIGGS, HEPMASS, etc.)</td> <td>Particle physics – Simulated collision events labeled as Higgs vs. background</td> <td>Numerical (tabular features)</td> <td>Graduate/Research</td> <td><a href="https://mlphysics.ics.uci.edu/#:~:text=HIGGS%20dataset">Open</a> (UCI/Zenodo)</td> </tr> <tr> <td><strong>LIGO/Virgo GWOSC</strong></td> <td>Gravitational waves – Time-series signals from interferometers (event strain data)</td> <td>Numerical (time-series)</td> <td>Frontier research</td> <td><a href="https://gwosc.org/eventapi/">Open</a> (GWOSC portal)</td> </tr> <tr> <td><strong>Quantum Optics Experiments</strong></td> <td>Quantum optics – e.g. single-photon interference, trapped-ion measurements</td> <td>Numeric (experimental logs, time-series)</td> <td>Graduate/Research</td> <td>Limited open (lab repositories, e.g. <a href="https://github.com/eperrier/QDataSet">QDataSet</a>)</td> </tr> <tr> <td><strong>Fluid Dynamics/CFD Simulations</strong></td> <td>Classical mechanics – CFD simulation outputs (e.g. flow fields, turbulence)</td> <td>Numerical (grids, images)</td> <td>Graduate/Research</td> <td>Partially open (benchmarks, e.g. NASA CFD data)</td> </tr> <tr> <td><strong>Graph Network Simulations</strong></td> <td>Multi-body physics – Synthetic trajectories for n-body, fluids, rigid bodies (<a href="https://community.arm.com/arm-community-blogs/b/mobile-graphics-and-gaming-blog/posts/physics-simulation-graph-neural-networks-targeting-mobile#:~:text=%E2%80%9CLearning%20to%20Simulate%E2%80%9D%20also%20presents,term%20interaction%20data">Physics Simulation With Graph Neural Networks Targeting Mobile - Mobile, Graphics, and Gaming blog - Arm Community blogs - Arm Community</a>)</td> <td>Numeric (graph-based, trajectories)</td> <td>Undergrad–Graduate</td> <td><a href="https://hal.science/hal-03806092/document">Partially open</a> (code to generate; DeepMind GNS data)</td> </tr> </tbody> </table> <h3 id="mathematics-for-physics">Mathematics for Physics</h3> <p>Datasets of mathematical problems, proofs, and symbolic computations relevant to physics problem-solving and theory.</p> <table> <thead> <tr> <th>Dataset / Source</th> <th>Domain &amp; Content</th> <th>Type</th> <th>Level</th> <th>Availability</th> </tr> </thead> <tbody> <tr> <td><strong>MATH Dataset</strong> (Hendrycks et al.)</td> <td>12,500 competition math problems with step-by-step solutions (<a href="https://arxiv.org/abs/2103.03874#:~:text=,though%20we%20are%20able%20to">[2103.03874] Measuring Mathematical Problem Solving With the MATH Dataset</a>)</td> <td>Text (problem ⇒ solution)</td> <td>Undergrad (contest)</td> <td><a href="https://github.com/hendrycks/math">Open</a> (public dataset)</td> </tr> <tr> <td><strong>PhysQA</strong></td> <td>1,008 physics word problems (mechanics, etc.) with annotated solutions</td> <td>Text (word problems Q\&amp;A)</td> <td>High school</td> <td><a href="https://arxiv.org/pdf/2309.08182">Open</a> (original: paperswithcode.com)</td> </tr> <tr> <td><strong>GPT-4 Physics Q\&amp;A (Camel Physics)</strong></td> <td>20,000 physics problem–solution pairs generated by GPT-4 (<a href="https://huggingface.co/datasets/camel-ai/physics#:~:text=Dataset%20Summary">camel-ai/physics · Datasets at Hugging Face</a>)</td> <td>Text (QA, synthetic)</td> <td>Undergrad–Grad (mixed)</td> <td>Open (Hugging Face)</td> </tr> <tr> <td><strong>Formal Theorem Libraries</strong></td> <td>Proofs and theorems (<a href="https://isabelle.in.tum.de/">Isabelle</a>, <a href="https://leanprover-community.github.io/">Lean</a>, <a href="https://github.com/uhub/awesome-coq">Coq libraries</a>) – e.g. analysis, algebra used in physics</td> <td>Formal text (logic)</td> <td>Graduate–Research</td> <td>Open (MIT/BSD licenses)</td> </tr> <tr> <td><strong>Symbolic Integration &amp; ODE Sets</strong></td> <td>Large sets of integrals and differential equations for symbolic solving (e.g. 27M integration pairs)</td> <td>Symbolic (expressions)</td> <td>Undergrad–Grad</td> <td>Open (research, <a href="https://github.com/mfbalin/SIRD-Symbolic-Integration-Rules-Dataset?tab=readme-ov-file">SIRD</a> dataset)</td> </tr> <tr> <td><strong>PINN Benchmark (PINNacle)</strong></td> <td>20+ distinct physics PDEs (heat eq., Navier-Stokes, etc.) with solution data for PINNs (<a href="https://arxiv.org/abs/2306.08827#:~:text=,fluid%20dynamics%2C%20biology%2C%20and">PINNacle: A Comprehensive Benchmark of Physics-Informed Neural …</a>)</td> <td>Numerical (PDE solutions)</td> <td>Undergrad–Grad</td> <td><a href="https://github.com/i207M/PINNacle">Open</a> (benchmark dataset)</td> </tr> </tbody> </table> <h3 id="multimodal-physics-data">Multimodal Physics Data</h3> <p>Combining text, equations, and visuals.</p> <ul> <li> <p><strong>MM-PhyQA (Multimodal Physics QA):</strong> High-school physics questions each with multiple related images and diagrams (<a href="https://arxiv.org/html/2404.08704v1#:~:text=While%20Large%20Language%20Models%20,for%20questions%20consisting%20of%20multimodal">MM-PhyQA: Multimodal Physics Question-Answering With Multi-Image CoT Prompting</a>). <em>Type:</em> Text + images; <em>Level:</em> High school; <em>Availability:</em> Open (research).</p> </li> <li> <p><strong>Physics StackExchange Q\&amp;A:</strong> Community Q\&amp;A with conceptual explanations (text, some diagrams). <em>Type:</em> Text (informal); <em>Level:</em> Undergraduate+; <em>Availability:</em> Open (CC license).</p> </li> <li> <p><strong>Laboratory Video/Imagery:</strong> E.g. cloud chamber images, astronomical images with annotations. <em>Type:</em> Visual + metadata; <em>Level:</em> Graduate; <em>Availability:</em> Partially open (scattered repositories).</p> </li> </ul> <p>The tables above show that many <strong>open-access datasets</strong> exist, especially for high-energy physics, mathematical problems, and certain simulations. Also note <strong>commercial/restricted datasets</strong> like proprietary textbook problem banks, paywalled journal corpora, or private experimental data (e.g. active experimental runs not yet released).</p> <p>Datasets have been used to train a variety of AI models: large language models (using text corpora of physics papers and Q\&amp;A), graph neural networks (using simulation or detector data structured as graphs), symbolic regression models (using formula datasets like Feynman), and physics-informed neural networks (using synthetic PDE solution datasets).</p> <h2 id="gap-analysis-missing-or-underrepresented-data">Gap Analysis: Missing or Underrepresented Data</h2> <p>Despite the above resources, I believe that several important gaps remain:</p> <ul> <li>We lack large, <strong>well-annotated datasets of physics problems</strong> at advanced graduate level, with step-by-step solutions. Existing collections like MATH or PhysQA cover contests or high-school problems, but few cover the multi-step derivations typical in university physics courses (e.g. electromagnetism, quantum mechanics problem sets) with detailed solutions.</li> <li>There is an <strong>absence of curated datasets of theoretical physics knowledge</strong> beyond raw text in papers. For example, there is no database of all important equations/derivations in quantum field theory or general relativity with context, proofs, etc. Similarly, while formal math libraries exist, they rarely cover <em>physics-specific</em> theorems or derivations (e.g. proofs of Noether’s theorem, derivations of field equations…).</li> <li>Niche but important domains like <strong>string theory, quantum gravity, or high-dimensional theoretical constructs are underrepresented</strong> in accessible data. For instance, the Kreuzer–Skarke dataset (Calabi–Yau spaces) exists but lacks labels connecting to physical phenomenology.</li> <li>Physics understanding often requires linking equations, diagrams, and natural language. <strong>Few datasets integrate multiple modalities</strong> – for example, pairing physics textbook figures or experimental plots with explanatory text and underlying equations. The lack of such unified multimodal datasets means AI struggles with tasks like interpreting a diagram alongside text or deriving equations from experimental graphs.</li> <li>There is a gap in <strong>datasets that directly connect experimental data with theoretical predictions</strong> in a structured way. While experimental data (like LHC events or LIGO signals) exist, they are not commonly packaged with the corresponding simulated or theoretical model outputs for the same conditions. This makes it difficult for AI to learn how theory parameters influence data and vice versa. A benchmark that pairs raw experimental data with the expected outcomes from theory (or simulation) is largely missing.</li> </ul> <p>Each of these gaps points to an opportunity for new dataset creation.</p> <h2 id="bridging-the-data-gap-in-theoretical-physics">Bridging the Data Gap in Theoretical Physics</h2> <p>The datasets reviewed illustrate both the progress made and the potential for advancing theoretical physics. Filling the identified gaps could catalyze breakthroughs. Just as ImageNet revolutionized computer vision, well-crafted physics datasets could similarly drive transformative developments in physics and AI.</p> <p>I think the task is clear: Physicists and data scientists need to collaborate to create accessible, comprehensive datasets addressing these gaps. Such datasets will not only enhance AI’s capability to understand and predict physics but also foster innovation, potentially accelerating the frontiers of science itself.</p>]]></content><author><name></name></author><category term="Machine"/><category term="Learning"/><category term="AI,"/><category term="Enterprise,"/><category term="Machine"/><category term="Learning,"/><category term="Business"/><summary type="html"><![CDATA[There is a lack of curated datasets in theoretical physics to train better machine learning models. But what exactly is missing and how can we fill the gaps?]]></summary></entry><entry><title type="html">Selected ideas from NeurIPS 2024</title><link href="https://manuelsh.github.io/blog/2025/Selected-ideas-from-NeurIPS2024/" rel="alternate" type="text/html" title="Selected ideas from NeurIPS 2024"/><published>2025-02-01T12:00:00+00:00</published><updated>2025-02-01T12:00:00+00:00</updated><id>https://manuelsh.github.io/blog/2025/Selected-ideas-from-NeurIPS2024</id><content type="html" xml:base="https://manuelsh.github.io/blog/2025/Selected-ideas-from-NeurIPS2024/"><![CDATA[<p><span style="color: grey; font-weight: 300; font-size: 0.9em;">1st February 2025</span> <a href="https://neurips.cc/Conferences/2024">NeurIPS</a> is widely considered <em>the</em> major AI research conference. With over 16,000 participants, 56 workshops, countless parallel tracks, and a staggering 3,650 posters, this event is more than just a conference: it offers a privileged vantage point into the state of the art in the field and their current challenges. The 2024 edition was hosted in Vancouver, during 6 packed days.</p> <p>While it’s impossible to capture its vast scope in a single post, here’s a glimpse of the most exciting ideas that stood out to me.</p> <h1 id="agents-the-next-frontier">Agents, the next frontier</h1> <p>Advancing intelligent systems requires shifting focus from standalone models (e.g., LLMs) to more complex, agent-based architectures capable of autonomous reasoning and decision-making. See for example the latest releases of frontier labs, such as o1 from OpenAI, DeepSeek, etc, where agentic methods like Chain of Thought are becoming more common.</p> <p>There were many interesting presentations on the topic, including showcases of agentic libraries, such as<a href="https://neurips.cc/Expo/Conferences/2024/workshop/100326">Autogen</a>, presented by Microsoft, or <a href="https://neurips.cc/Expo/Conferences/2024/workshop/100321">Llama Stack</a>, by the folks of Meta.</p> <h2 id="conquering-human-user-interfaces">Conquering human user interfaces</h2> <p><a href="https://microsoft.github.io/OmniParser/">OmniParser</a>, also from Microsoft, is a promising framework that provides more information to a multimodal LLM about the content of a screen or browser, drastically facilitating the interaction of the model with user interfaces. Solving this problem is key to have true agents in our phones or computers.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/omniparser_example-480.webp 480w,/assets/img/blog_images/omniparser_example-800.webp 800w,/assets/img/blog_images/omniparser_example-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/omniparser_example.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Example of the output of Omniparser from a screenshot with Google Slides. </div> <p>A key limitation, as I have observed in my own tests, is that feeding raw screenshots or HTML to a multimodal LLM (e.g., GPT4V) and granting it control over the mouse and keyboard results in poor performance on UI-driven tasks like booking flights or hotels. This is reflected in the low accuracy on GUI task oriented benchmarks, such as the <a href="https://web.archive.org/web/20250317225153/https://paperswithcode.com/sota/natural-language-visual-grounding-on">ScreenSpot benchmark</a>, where GPT4V arrives to 16% accuracy.</p> <p>However, if the model is supplemented with the input coming from Omniparser, accuracy jumps to 73% on the same dataset. This has been surpassed <a href="https://web.archive.org/web/20250317225153/https://paperswithcode.com/sota/natural-language-visual-grounding-on">by other models</a>, which means that in less than one year, we will likely see AI operating seamlessly with the UI of our phones or computers as humans do.</p> <h2 id="other-useful-resources-about-agents">Other useful resources about Agents</h2> <p>The folks of Meta showed how to build agents with their <a href="https://github.com/meta-llama/llama-stack">Llama Stack</a>, providing also a great <a href="https://colab.research.google.com/drive/1F2ksmkoGQPa4pzRjMOE6BXWeOxWFIW6n#scrollTo=K4AvfUAJZOeS">notebook with many relevant examples</a>, which includes RAG evaluation with LLM as a judge.</p> <p>A key highlight was their proposed agentic architecture, which features a central executor coordinating all operations, as illustrated below. Just follow the numbers in order to better understand it.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/Meta_agentic_archirecture_proposal.JPG" sizes="95vw"/> <img src="/assets/img/blog_images/Meta_agentic_archirecture_proposal.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Architecture of an agent as proposed by Meta. Source: Active Training: Building Agentic Apps with Llama 3.2 and Llama Stack. Neurips 2024. </div> <p>They also provided some hints on which model size to use for different tasks. The following table is quite useful.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/Meta_model_sizes_and_usages_table.JPG" sizes="95vw"/> <img src="/assets/img/blog_images/Meta_model_sizes_and_usages_table.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Table showing the model sizes and their usages as proposed by Meta. Source: Active Training: Building Agentic Apps with Llama 3.2 and Llama Stack. Neurips 2024. </div> <h1 id="building-and-improving-large-language-models">Building and improving Large Language Models</h1> <p>One of the standout topics at NeurIPS this year was the process of building and improving Large Language Models. A particularly noteworthy presentation was given by the AllenAI team, who provided a <a href="https://neurips.cc/virtual/2024/tutorial/99526">detailed overview of the end-to-end process of building an LLM</a>. From data acquisition to post-training, they shared many insights and tips. This topic is so rich that it deserves a summary of its own, which you can find <a href="https://manuelsh.github.io/blog/2025/NIPS-building-llm-workshop/">here</a>.</p> <h2 id="are-we-running-out-of-data">Are we running out of data?</h2> <p>A recurring theme was data scarcity. Kyle Lo from AllenAI clarified that while data itself isn’t vanishing, open-access data is becoming increasingly limited. Ilya Sutskever, in his remarks upon receiving the “Test of Time Award” for his paper, described data as the “fossil fuel of AI,” noting that while compute continues to grow, data is not growing at the same pace. He suggested that we should be looking at “synthetic data,” inference time compute, and agents as potential solutions.</p> <p>This was challenged by Jason Weston, who pointed out that significant portion of the training of LLMs in frontier companies relies on “closed data,” which they possess and are generating in substantial quantities. He expressed skepticism about the severity of the data scarcity issue, suggesting that Ilya’s perspective might be influenced by his recent departure from OpenAI and the resulting loss of access to that data.</p> <p>It is worth mentioning the work of Epoch AI. In their <a href="https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data">Will We Run Out of Data?</a> paper they project that human public text, estimated in 300 trillion tokens, will be fully utilized between 2026 and 2032, or earlier (see chart below).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/epoch-ai-data-utilization-480.webp 480w,/assets/img/blog_images/epoch-ai-data-utilization-800.webp 800w,/assets/img/blog_images/epoch-ai-data-utilization-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/epoch-ai-data-utilization.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Source: Epoch AI, June 2024 </div> <p>Epoch AI focuses in this study on textual data. However, a significant portion of data exists in other formats, such as images, audio, and video, which can also be used for training.</p> <p>While computational power grows exponentially and data increases at a linear rate, algorithms and methods continue to become more efficient. Furthermore, alternatives like self-distillation (model generates data and trains with it), <a href="https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback">Constitutional AI</a>, synthetic data, and private datasets reduce this reliance on high data volume. For all these reasons I don’t think data will be the main bottleneck.</p> <h2 id="architectures-and-rl-methods">Architectures and RL methods</h2> <p>It’s clear that other alternatives to the Transformer architecture are standing out, such as <a href="https://arxiv.org/abs/2312.00752">Mamba</a> or <a href="https://neurips.cc/virtual/2024/invited-talk/101129">xLSTM</a>. These architectures are more efficient that the Transformer at inference, as the computing doesn’t grow quadratically with the number of input tokens, while they can parallelize the prediction of the next token in the training, like the Transformer does, instead of sequentially like previous architectures (RNN, LSTM…). Sepp Hochreiter, the creator of LSTM, presented xLSTM, acknowledging its strong resemblance to Mamba.</p> <p>However, although these arechitectures were mentioned many times, in practice they are not yet widely used.</p> <p>Additionally, <a href="https://huggingface.co/blog/rlhf">Reinforcement Learning with Human Feedback</a> (or RLHF), which is the method used by OpenAI ChatGPT to make a language model a chatbot, is being substituted or supplemented by many other methods, like DPO, which is significantly easier and performs at a similar level. More details in my summary on <a href="https://manuelsh.github.io/blog/2025/NIPS-building-llm-workshop/">Opening the LLM pipeline</a>.</p> <h1 id="measuring-the-performance-of-foundation-models">Measuring the performance of foundation models</h1> <p>Although benchmarking models is part of building models, this topic is so important that requires its own section. Benchmarking is not only important to understand how well a model performs but building relevant benchmarks is key to advance the field.</p> <h2 id="benchmarks-to-advance-ai">Benchmarks to advance AI</h2> <p>The definition of intelligence is ellusive, that is why those benchmarks that are easy for humans but hard for AI models are critical, as they establish a new baseline to beat. One of them is <a href="https://arcprize.org/">ARC</a>, which requires the ML model to solve a series of puzzles, each one with a different logic, like the one shown below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/ARC-benchmark_example.svg" sizes="95vw"/> <img src="/assets/img/blog_images/ARC-benchmark_example.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Example of an ARC puzzle. Source: https://lab42.global/arc/ </div> <p>The performance of humans in the ARC test is very high, around 90% accuracy according to the ARC team, while at the time of Neurips 2024 the best model was at 53%. Interestingly, less than a week after François Chollet presentation in NeurIPS, OpenAI announced that their <a href="https://web.archive.org/web/20250323011500/https://community.openai.com/t/day-12-of-shipmas-new-frontier-models-o3-and-o3-mini-announcement/1061818">new o3 model</a> is able to reach to 76% in ARC. A great example of how quickly the field moves!</p> <p><a href="https://melaniemitchell.me/">Melanie Mitchell</a>, from the Santa Fe Institute, also showed during a workshop about <a href="https://neurips.cc/virtual/2024/workshop/84749">System-2 reasoning</a> how current state of the art LLMs fail when some benchmarks are modified in trivial ways. She mentioned an example of the paper <a href="https://arxiv.org/pdf/2307.02477">Reasoning or Reciting?</a> where in a Python code benchmark, where GPT4 can perform very well, just by introducing a simple change in the way the language works (“now lists index start with one and not zero) the model performance drops drastically. See the chart below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/reasoning-or-reciting-benchmark-paper-neurips-post-480.webp 480w,/assets/img/blog_images/reasoning-or-reciting-benchmark-paper-neurips-post-800.webp 800w,/assets/img/blog_images/reasoning-or-reciting-benchmark-paper-neurips-post-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/reasoning-or-reciting-benchmark-paper-neurips-post.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> GPT4 performance on the default version of various benchmarks and in the modified version (counterfactuals). Source: Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks. Wu et al. March 2024. </div> <p>Building “easy for humans, hard for AI” kind of benchmarks are key to the development of more intelligent models. Indeed, as Fei Fei pointed out in <a href="https://neurips.cc/virtual/2024/invited-talk/101127">her inspiring presentation</a> (highly recommended!), the ImageNet benchmark that she created was a key element for the rebirth of neural networks in 2012, and the newly coined term “Deep Learning”.</p> <h2 id="eureka-a-comprehensive-framework-to-evaluate-llms">EUREKA: A comprehensive framework to evaluate LLMs</h2> <p>The folks from Microsoft <a href="https://neurips.cc/Expo/Conferences/2024/talk%20panel/105693">presented</a> a comprehensive and open source framework to evaluate multimodal and language models called <a href="https://www.microsoft.com/en-us/research/blog/eureka-evaluating-and-understanding-progress-in-ai/">Eureka</a>, which assesses the performance of models across several dimensions. Some of the main conclussions of their evaluation of 14 large foundation models are:</p> <ul> <li>Models like Claude 3.5 Sonnet, GPT-4o 2024-05-13, and Llama 3.1 405B show distinct strengths in specific tasks but are not universally superior across all benchmarks. This highlights the need for task-specific analysis rather than assuming a model’s overall superiority.</li> <li>Current AI models struggle significantly with multimodal tasks, particularly those requiring detailed image understanding and spatial reasoning. For example, all models perform poorly on Object Detection.</li> </ul> <p>In the folllowing chart you check see the results for both language and multimodal tasks.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/eureka-benchmark-framework-neurips-post-480.webp 480w,/assets/img/blog_images/eureka-benchmark-framework-neurips-post-800.webp 800w,/assets/img/blog_images/eureka-benchmark-framework-neurips-post-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/eureka-benchmark-framework-neurips-post.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Performance of best and worse models for multimodal (left) and language (right) datasets in in Eureka-Bench. Note the room to improve in Object Detection, Information Retrieval or navigation. Source: Eureka: Evaluating and Understanding Progress in AI. Microsoft Research, NeurIPS 2024. </div> <h1 id="unified-representations-shedding-light-on-the-black-box">Unified Representations, shedding light on the black box</h1> <p>Significant progress have been done on the topic of understanding how neural networks (human and artificial) encodes and process information. Several illuminating ideas around the topic were presented in the <a href="https://neurips.cc/virtual/2024/workshop/84701">UniReps Workshop</a> at NeurIPS 2024.</p> <h2 id="the-platonic-representation">The platonic representation</h2> <p>We have substantial evidence that different neural networks, including artificial and human neural networks, converge towards the same way of representing the world. This evidence comes by looking at the multidimensional spaces that the activations of the layers of neural networks produce (an embedding) when a concept is used as input. In <a href="https://arxiv.org/abs/2405.07987">The Platonic Representation Hypothesis</a> paper, authors observed that the spaces generated by embeddings of different models have very similar characteristics: for example the distances between points of the same concepts (e.g. distance between the concepts <em>pear</em> and <em>giraffe</em>) in a language model or in a vision model remain very similar, and this similarity increases the better the models are. See chart below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/alignment_unified_representations_neurips_2024-480.webp 480w,/assets/img/blog_images/alignment_unified_representations_neurips_2024-800.webp 800w,/assets/img/blog_images/alignment_unified_representations_neurips_2024-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog_images/alignment_unified_representations_neurips_2024.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The better the models, the more aligned are their representations. Source: Phillip Isola, Unireps, NeurIPS 2024 </div> <p>Not only that, but there is evidence that the same happens with the activation of our neurons in our brain. They also generate a space that is similar to the ones of the frontier models, and we can even use LLM to interpret the output of this human brain activations.</p> <p>A profound question arises: is there a unique <em>platonic representation</em> that models and humans converge to? Knowing it could help building more intelligent models. If you find this material interesting, I recommend reading <a href="https://phillipi.github.io/prh/#what_converging_to">the summary of the paper</a>.</p> <p>Having internal representations encoded as perpendicular vectors also leads to conclude that a neural computation is a transformation of a representation into another representation. That’s the job of the neural network weight and biases, to transform the input representation (usually in the form of learned embeddings) into another representation that is useful for the task at hand. Incredible the power of linear algebra and some non-linearities!</p> <h2 id="reverse-engineerig-intelligence">Reverse engineerig intelligence</h2> <p>Many other talks in this workshop where about gaining a further understanding of the mechanics of the brain and neural networks. For example, they discovered that <a href="https://arxiv.org/pdf/2409.05771">middle layers of LLMs are better to predict</a> the concepts behind human brain activations. There is evidence that LLMs, in order to predict the next token, generate first an internal representation that encodes many functions of the language (which is in the middle layers), which is richer, versus the represenation that just predict the next token, in the final layers.</p> <p>There is also strong evidence that neural networks encode information in “directions” in a multidimensional space, where each useful abstract concept (for example, the language a text is written in) is encoded in a different direction, each one “almost” perpendicular to each other, which is possible in a multidimensional space (in a 3d space, there are only 3 dimenspossible perpendicular vectors, but in higher dimensions space, if we relax the constraint of perpendicularity from 90 degrees angle to 89-91 degrees, the amount of almost perpendicular vectors grow exponentially with the number of dimensions). Highly recommended to watch this lesson of ThreeBlueOneBrown on <a href="https://www.3blue1brown.com/lessons/mlp">How might LLM store facts</a>. In fact, watch all the Deep Learning videos of this channel, they are the best I’ve seen explaining the concepts of the transformer.</p> <p>Very interesting also the Mechanistic Interpretability talk of <a href="https://www.neelnanda.io/">Neel Nanda</a>, from DeepMind. Mechanistic Interpretability aspires to reverse engineer neural networks, working on the hypothesis that models learn human comprehensible structures that can be understood. He showed an example where they are able to identify a “direction in space” that encodes refusal, i.e. when the model refuses to speak about certain topic, usually because of the safety constraints. Knowing this direction, they are able to deactivate it, just by subtracting that vector, allowing the model to respond on originally unintended ways. This refusal direction appears in every model they checked, is almost universal.</p> <p>One clear application of better understanding the inner workings of neural networks is to improve their safety. Which lead us to the next topic.</p> <h1 id="ai-safety-advocating-for-tools-not-agents">AI Safety: advocating for tools, not agents</h1> <p><a href="https://yoshuabengio.org/">Youshua Bengio</a> and <a href="https://physics.mit.edu/faculty/max-tegmark/">Max Tegmark</a> participated in a <a href="https://neurips.cc/virtual/2024/workshop/84705">relevant workshop on AI safety</a>. One of their main arguments was that AI’s benefits can be maximized while minimizing risks by developing specialized models rather than fully autonomous agents. A great example of this is the <a href="https://deepmind.com/research/case-studies/alphafold">AlphaFold</a> model, which is a tool that helps scientists to predict the 3D structure of proteins; key for drug discovery and currently widely used.</p> <h1 id="foundation-models-for-e-commerce">Foundation models for E-commerce</h1> <p>The folks from Shopify presented an initiative to build a <a href="https://neurips.cc/Expo/Conferences/2024/talk%20panel/100357">foundation model for e-commerce</a>, which takes a selection of events as inputs (these are the tokens), and try to predict following events. The idea is that such a model takes many functions of a typical e-commerce platform, like recommendedr system, fraud detection, next best intervention, etc.</p> <p>They presented a couple of architecture choices to address the problem, <a href="https://arxiv.org/abs/2402.17152v1">HSTU</a>, and <a href="https://arxiv.org/abs/2305.05065">TIGER</a>. What is promising about their work is that they mention an uplift of 240-480% recall@10 in <em>offline experiments</em>. I am looking forward to see the results once models are deployed in production.</p> <h1 id="concluding-remarks">Concluding remarks</h1> <p>The scale of NeurIPS 2024 is a testament to the rapid growth of the field of AI. The conference showcased a wide range of ideas and approaches, from the development of large language models to the exploration of new architectures and reinforcement learning methods. The presentations on agents and the development of tools for AI safety were particularly thought-provoking, highlighting the potential for AI to transform our world in the coming years.</p> <p>As a final thought, consider that human intelligence, the most advanced we know (so far), processes 50-100 terabytes of sensory data annually, all powered by a brain consuming just ~20 Watts. This sets an ambitious benchmark for AI systems to aspire to.</p>]]></content><author><name></name></author><category term="NeurIPS,"/><category term="LLM,"/><category term="Generative"/><category term="AI,"/><category term="Machine"/><category term="Learning"/><category term="LLM,"/><category term="NeurIPS"/><summary type="html"><![CDATA[NeurIPS 2024, the largest AI research conference, provides a glimpse into the next frontiers. Here are some of the most exciting ideas presented.]]></summary></entry><entry><title type="html">Opening the LLM pipeline</title><link href="https://manuelsh.github.io/blog/2025/NIPS-building-llm-workshop/" rel="alternate" type="text/html" title="Opening the LLM pipeline"/><published>2025-01-03T12:00:00+00:00</published><updated>2025-01-03T12:00:00+00:00</updated><id>https://manuelsh.github.io/blog/2025/NIPS-building-llm-workshop</id><content type="html" xml:base="https://manuelsh.github.io/blog/2025/NIPS-building-llm-workshop/"><![CDATA[<p><span style="color: grey; font-weight: 300; font-size: 0.9em;">3rd January 2025</span> This post summarizes a fanstic tutorial about building LLM, titled <a href="https://neurips.cc/virtual/2024/tutorial/99526">“Opening the Language Model Pipeline: A Tutorial on Data Preparation, Model Training, and Adaptation”</a> (<a href="https://docs.google.com/presentation/d/179dpzWSQ9G7EAUlvaJdeE0av9PLuk9Rl33nfhHSJ4xI/edit#slide=id.g30a4c7e9678_0_0">slides</a>). It was presented at NeurIPS 2024, by <a href="https://kyleclo.com/">Kyle Lo</a>, <a href="https://akshitab.github.io/">Akshita Bhagia</a> and <a href="https://www.natolambert.com/">Nathan Lambert</a>, all from the <a href="https://allenai.org/">Allen Institute for AI</a>. I think it could be useful to share some of the main ideas.</p> <p>The process to build a Large Language Model is very involved, and the authors went through it end to end, providing many details and practical knowledge: starting with the data preparation, continuing wiht model training (also called pre-training), and adaptation (or post-training). Here I summarize the main takeaways from each part, with some additional notes added.</p> <h2 id="data-preparation">Data preparation</h2> <p>Data preparation mainly means data acquisition, data transformation (deduplication, quality control, etc) and data evaluation.</p> <h3 id="data-acquisition">Data acquisition</h3> <p>To acquire data, crawling is common. However, it’s <a href="https://www.dataprovenance.org/Consent_in_Crisis.pdf">becoming harder to crawl data</a>. Many websites are opting out or implementing anti crawlers protection, as shown in the figure below. Note that this will create a barrier to enter for new players. As Kyle Lo said: we are not running out of data, we are running out of <em>open</em> data.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/crawling_data.JPG" sizes="95vw"/> <img src="/assets/img/blog_images/crawling_data.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Longpre et. al. 2024. Consent in Crisis: The Rapid Decline of the AI Data Commons. Data Provenance Initiative. </div> <p>Crawling data from websites implies, for many of them, understanding the JavaScript logic, which in many cases is unique to the website. This can be challenging because each website may use different frameworks or obfuscation techniques, making it necessary to decipher custom implementations. For example, a site might load data dynamically through complex API calls embedded in asynchronous scripts, requiring tailored solutions for successful extraction. It also requires to parse the data from all the HTML, which is not easy. For PDF’s or scanned documents is also difficult, as many tools are not able to parse the data correctly.</p> <h3 id="data-transformation">Data transformation</h3> <p>That mostly means language filtering, deduplication, removing sensitive content (including private content) and ensuring a desired quality. In reality, it’s a classification problem, and can be done using machine learning with small classifiers. They recommend the library <a href="https://github.com/facebookresearch/fastText">fastText</a>, which is quite efficient (and used across the industry), although more involved classifiers can be used.</p> <p>They also shared the amount of data that remains once the data is filtered for quality and deduplication: reductions are usually of the order of 65 times.</p> <p>Filtering for quality can be, in some cases, problematics, as one can be undesiringly removing specific themes which are usually classified as lower quality, e.g. high school related content.</p> <p>It is also quite difficult to remove personal data, as it was highlighted by <a href="https://aclanthology.org/2023.trustnlp-1.18.pdf">Subramani et al (2023)</a>, where they showed that accuracies with simple Regex or tools like <a href="https://microsoft.github.io/presidio/">Presidio</a> can be quite low.</p> <h3 id="data-evaluation">Data evaluation</h3> <p>Finally, data must be evaluated by training models and running benchmarks, such as MMLU, HumanEval, GSM8K… The evaluation should be done systematically to each group of data, ideally starting with a smaller and cheaper mode. In general it is a very involved process with many nuances, like what is the best model size, measuring the effect of your data filtering, etc</p> <h3 id="a-new-trend-data-curriculum">A new trend: data curriculum</h3> <p>Some interesting new trend: “data curriculum”, which consists of, after training the model with trillions of tokens (high quantity, less quality), at the end of it one switches data to either very high quality sources, specific instructions or synthetic data.</p> <h2 id="model-training-or-pre-training">Model training (or pre-training)</h2> <p>Pre-training, the process where you train a LLM on next token prediction with a large amount of text, is currently mostly done with a Transformer architecture, accepting many different configurations that are successful, including many attention mechanisms (e.g. multi head, grouped-query or multi-query). See image below, how different configurations of the hyperparameters (marked in red) can lead to successful models.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/LLM_hyperparameter_configuration.JPG" sizes="95vw"/> <img src="/assets/img/blog_images/LLM_hyperparameter_configuration.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Different configurations of the hyperparameters (marked in red) can lead to successful models. From the tutorial authors. </div> <p>In terms of scale the approximate good scaling law given by the <a href="https://arxiv.org/abs/2203.15556">Chinchilla paper</a> (compute budget approximately 6 times the number of parameters by data tokens, and data tokens approx 20 times the number of parameters), although in practice everybody keeps training further.</p> <p>In terms of costs, the pre-training can be very expensive, as it is very intensive in computational resources. See for example the table below, by the authors of the tutorials: a 7b parameter model and 150B tokens (just above the Chinchilla paper budget), will cost approx $10k.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/cost_of_LLM_training.JPG" sizes="95vw"/> <img src="/assets/img/blog_images/cost_of_LLM_training.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Costs for different models and data sizes. From the tutorial authors. </div> <p>Common positional embeddings today are <a href="https://arxiv.org/abs/2104.09864">rotary positional embeddings</a> (RoPE) and the <a href="https://arxiv.org/abs/2002.05202v1">SwiGLU activation</a>, which, unlike ReLU activation, is smooth (differentiable) at zero.</p> <h3 id="problems-with-loss-function-convergence">Problems with loss function convergence</h3> <p>When the loss function spikes punctually, look at your data, probably is a low quality batch that needs to be filtered.</p> <p>When the loss function starts spiking and diverging, one needs to ensure that the scale of activations and gradients remain roughly the same, and they should scale with model width. Better to use normal initialization and RMSNorm, QK-Norm and change the order of the layer norm. Finally, ensure that the token embedding does not become too small (no weight decay).</p> <p>Run experiments with smaller models first, to find optimal parameters, decide on data ablations.</p> <h3 id="additional-tips-for-pre-training">Additional tips for pre-training</h3> <p>Learning rate annealing also helped. Increase first with the first 10B tokens (to 3e-4) then reduce with cosine decay to 5e-5 for the following trillions of tokens and finally reduce to 0 in the last 50B tokens (e.g. with curriculum training).</p> <p>Use efficient architectures such as Mixture of Experts.</p> <p>In terms of distributing the training across GPU’s, the recommendation is to use FSDP. Here there is an <a href="https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html">excellent tutorial</a>. One needs to ensure that the global batch size is not too large.</p> <p>Use <a href="https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad">flash attention</a> algorithm as is faster and more memory efficient. Try to keep your code simple, before using torch.compile.</p> <p>With large training jobs it’s important to manually do garbage collection at the same time in all processes, as otherwise you can have stalls.</p> <h2 id="adaptation-or-post-training">Adaptation (or post-training)</h2> <p>The output of the pre-training is not ready for use, as it is just predicting the next token. The model needs to be adapted to the specific task at hand: this is the alignment problem: i.e. how we align the model behavior with the human preferences (or the specific task).</p> <p>The first step for adaptation is to have some target tasks (e.g. math, or writting code), with some meaningful evaluation, i.e. some specific benchmarks to evaluate. Then one needs to collect (or build) prompts that represent the task.</p> <p>Currently, in many open source LLMs, different process from <a href="https://openai.com/index/instruction-following/">Reinforcement Learning from Human Feedback</a> (RLHF), created by OpenAI, are used. In reality one can combine them, as we will see below.Some of these methods are:</p> <ul> <li><a href="https://arxiv.org/abs/2305.18290">Direct Preference Optimization</a> (DPO), much simpler with similar performance. It does not need a reward model (like RLHF), and requires only to optimize a modified version of a simple binary cross entropy objective. It is used in the <a href="https://arxiv.org/pdf/2407.21783">Llama 3 model</a>.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/dpo_summary_from_paper.JPG" sizes="95vw"/> <img src="/assets/img/blog_images/dpo_summary_from_paper.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> DPO vs RLHF. From [Direct Preference Optimization](https://arxiv.org/abs/2305.18290) paper. </div> <ul> <li> <p><a href="https://huggingface.co/blog/rishiraj/finetune-llms">Supervise Fine Tuning</a> (SFT) is a method that uses a supervised fine-tuning approach, where the model is fine-tuned on a small labeled dataset. It is used in the <a href="https://arxiv.org/pdf/2403.09611">MM1 model</a> from Apple.</p> </li> <li> <p><a href="https://www.interconnects.ai/p/tulu-3">Reinforcement Learning with Verifiable Rewards</a> (RLVR) is a quite simple but effective method coined by the authors, where they replace RLHF by a scoring function that offers positive rewards if the answer is correct. Only applicable (for now) in verifiable rewards, such as math problems with known answers.</p> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/RL_with+VR_schema.JPG" sizes="95vw"/> <img src="/assets/img/blog_images/RL_with+VR_schema.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Reinforcement Learning with Verifiable Rewards. From the tutorial authors. </div> <p>In terms of combining them, the authors of the tutorial suggest to start with SFT (e.g. ~1 million prompts), continue with DPO (another ~1 million prompts), and finally use Reinforcement Learning (~10k-100k prompts).</p> <h3 id="supervised-fine-tuning">Supervised Fine Tuning</h3> <p>With SFT you can get ~80% of performance gain in many tasks.</p> <p>Is used to adapt the pre-trained to specific styles of input, such as chat interactions, and can include system prompts, multi turn dialogues…</p> <p>A lot of data on this category has been created syntehtically by using LLMs to generate variations of human created prompts.</p> <p>Usually one start with mixing the existing datasets, evaluating with benchmarks, and on these benchmarks that are lagging, create new data (they usesd <a href="https://github.com/tencent-ailab/persona-hub">PersonaHub</a>).</p> <h3 id="preference-optimization-dpo">Preference Optimization (DPO)</h3> <p>Aligning to human preferences make the model stronger (e.g. ChatBotArena), allowing to control style.</p> <p>Preference optimization takes a prompt with a chosen and a rejected completion (by a human), and assumes that the probability of the chosen completion should be higher than the rejected one.</p> <p>Surprisingly low learning rates (~5E-7) are standard use. With a 70B parameter model the people from the Allen Institute were able to surpass GPT-4 in various benchmarks.</p> <h3 id="reinforcement-learning">Reinforcement Learning</h3> <p>Although more complex, it allows to normally get ~1% better performance. One can start with synthetic data (LLM-as-a-judge), that has low noise and high bias and then move to human data, with high noise but low bias.</p> <p>The leading synthetic preference data method is <a href="https://arxiv.org/abs/2310.01377v2">UltraFeedback</a>, where instructions are sampled from a large pool of models and GPT-4 is used to annotate preferences.</p> <p>They used the RLVR method, where there is no reward function but just a scoring function that offers positive rewards if the answer is correct. This is for now limited to math and precise instructions.</p> <h2 id="conclusions">Conclusions</h2> <p>The talk reminded me of other recent articles which describe the LLM building process (or at least provide some details), such as the very <a href="https://arxiv.org/pdf/2403.09611">insightful paper from Apple</a> about their MM1 model, or the <a href="https://arxiv.org/pdf/2407.21783">one from Meta on Llama 3.1</a>.</p> <p>The folks from the Allen Institute were very generous in sharing their knowledge, as I think many tips from their practical knowledge may be useful. They also shared <a href="https://github.com/allenai/awesome-open-source-lms">this repository</a> with many open source models and resources.</p> <p>I hope the video is shared soon in <a href="https://neurips.cc/virtual/2024/tutorial/99526">the tutorial page</a>.</p> <p><strong>Edit:</strong> <a href="https://www.natolambert.com/">Nathan Lambert</a> tells me that he re-recorded the last part of the tutorial, you can enjoy it here: <a href="https://www.interconnects.ai/p/the-state-of-post-training-2025">The state of post-training in 2025</a>.</p>]]></content><author><name></name></author><category term="NeurIPS"/><category term="LLM,"/><category term="NeurIPS"/><summary type="html"><![CDATA[My notes on a great tutorial at NeurIPS 2024 on how to build a Large Language Model, with many practical tips.]]></summary></entry><entry><title type="html">The path to AGI: quantifying bottlenecks</title><link href="https://manuelsh.github.io/blog/2024/the-path-to-agi-quantifying-bottlenecks/" rel="alternate" type="text/html" title="The path to AGI: quantifying bottlenecks"/><published>2024-10-06T20:03:33+00:00</published><updated>2024-10-06T20:03:33+00:00</updated><id>https://manuelsh.github.io/blog/2024/the-path-to-agi-quantifying-bottlenecks</id><content type="html" xml:base="https://manuelsh.github.io/blog/2024/the-path-to-agi-quantifying-bottlenecks/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Scaling artificial intelligence to new heights comes with significant challenges, particularly in hardware, energy, and data availability. As we strive towards Artificial General Intelligence (AGI), the hurdles grow—from the immense GPU requirements to the daunting energy consumption and even the scarcity of high-quality training data. These obstacles are demanding, yet they are not insurmountable, paving the way for ambitious innovations and new solutions.]]></summary></entry><entry><title type="html">Normalization in TensorFlow: speed is an issue</title><link href="https://manuelsh.github.io/blog/2018/normalization-in-tensorflow-speed-is-an-issue/" rel="alternate" type="text/html" title="Normalization in TensorFlow: speed is an issue"/><published>2018-02-27T10:24:39+00:00</published><updated>2018-02-27T10:24:39+00:00</updated><id>https://manuelsh.github.io/blog/2018/normalization-in-tensorflow-speed-is-an-issue</id><content type="html" xml:base="https://manuelsh.github.io/blog/2018/normalization-in-tensorflow-speed-is-an-issue/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Setting up your GPU TensorFlow platform</title><link href="https://manuelsh.github.io/blog/2017/setting-up-your-gpu-tensorflow-platform/" rel="alternate" type="text/html" title="Setting up your GPU TensorFlow platform"/><published>2017-06-11T15:10:34+00:00</published><updated>2017-06-11T15:10:34+00:00</updated><id>https://manuelsh.github.io/blog/2017/setting-up-your-gpu-tensorflow-platform</id><content type="html" xml:base="https://manuelsh.github.io/blog/2017/setting-up-your-gpu-tensorflow-platform/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">La materia al descubierto</title><link href="https://manuelsh.github.io/blog/2008/la-materia-al-descubierto/" rel="alternate" type="text/html" title="La materia al descubierto"/><published>2008-04-13T22:17:07+00:00</published><updated>2008-04-13T22:17:07+00:00</updated><id>https://manuelsh.github.io/blog/2008/la-materia-al-descubierto</id><content type="html" xml:base="https://manuelsh.github.io/blog/2008/la-materia-al-descubierto/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[En los primeros años del siglo XX se produjo una revolución extraordinaria en la física con el nacimiento de la mecánica cuántica, pero también se abrió un campo plagado de grandes interrogantes que mantienen intrigados a muchos físicos. Uno de los descubrimientos más sorprendentes fue que la luz, además de ser una onda, también se [&#8230;]]]></summary></entry><entry><title type="html">El nacimiento de la mecánica cuántica</title><link href="https://manuelsh.github.io/blog/2008/el-nacimiento-de-la-mecnica-cuntica/" rel="alternate" type="text/html" title="El nacimiento de la mecánica cuántica"/><published>2008-02-23T16:44:05+00:00</published><updated>2008-02-23T16:44:05+00:00</updated><id>https://manuelsh.github.io/blog/2008/el-nacimiento-de-la-mecnica-cuntica</id><content type="html" xml:base="https://manuelsh.github.io/blog/2008/el-nacimiento-de-la-mecnica-cuntica/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Cuando una teoría que intenta explicar la naturaleza comienza a dar resultados que no concuerdan con lo que medimos, ¡es un buen momento para cambiarla por otra nueva! Esta es la historia de cómo un truco matemático significó en realidad una nueva interpretación de la realidad: el nacimiento de la mecánica cuántica. Y ocurrió a [&#8230;]]]></summary></entry></feed>