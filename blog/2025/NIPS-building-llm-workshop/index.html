<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Opening the LLM pipeline | Manuel Sánchez Hernández </title> <meta name="author" content="Manuel Sánchez Hernández"> <meta name="description" content="My notes on a great tutorial at NeurIPS 2024 on how to build a Large Language Model, with many practical tips."> <meta name="keywords" content="machine-learning, artificial-intelligence, physics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?b05f9a0b7405d7c8c89c7465593dea81"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?dadeb9c5d1fd12bc8d37475657446863"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://manuelsh.github.io/blog/2025/NIPS-building-llm-workshop/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Opening the LLM pipeline",
            "description": "My notes on a great tutorial at NeurIPS 2024 on how to build a Large Language Model, with many practical tips.",
            "published": "January 03, 2025",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Manuel Sánchez Hernández </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Opening the LLM pipeline</h1> <p>My notes on a great tutorial at NeurIPS 2024 on how to build a Large Language Model, with many practical tips.</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#data-preparation">Data preparation</a> </div> <ul> <li> <a href="#data-acquisition">Data acquisition</a> </li> <li> <a href="#data-transformation">Data transformation</a> </li> <li> <a href="#data-evaluation">Data evaluation</a> </li> <li> <a href="#a-new-trend-data-curriculum">A new trend: data curriculum</a> </li> </ul> <div> <a href="#model-training-or-pre-training">Model training (or pre-training)</a> </div> <ul> <li> <a href="#problems-with-loss-function-convergence">Problems with loss function convergence</a> </li> <li> <a href="#additional-tips-for-pre-training">Additional tips for pre-training</a> </li> </ul> <div> <a href="#adaptation-or-post-training">Adaptation (or post-training)</a> </div> <ul> <li> <a href="#supervised-fine-tuning">Supervised Fine Tuning</a> </li> <li> <a href="#preference-optimization-dpo">Preference Optimization (DPO)</a> </li> <li> <a href="#reinforcement-learning">Reinforcement Learning</a> </li> </ul> <div> <a href="#conclusions">Conclusions</a> </div> </nav> </d-contents> <p>This post summarizes a very nice tutorial about building LLM, titled <a href="https://neurips.cc/virtual/2024/tutorial/99526" rel="external nofollow noopener" target="_blank">“Opening the Language Model Pipeline: A Tutorial on Data Preparation, Model Training, and Adaptation”</a> (<a href="https://docs.google.com/presentation/d/179dpzWSQ9G7EAUlvaJdeE0av9PLuk9Rl33nfhHSJ4xI/edit#slide=id.g30a4c7e9678_0_0" rel="external nofollow noopener" target="_blank">slides</a>). It was presented at NeurIPS 2024, by <a href="https://kyleclo.com/" rel="external nofollow noopener" target="_blank">Kyle Lo</a>, <a href="https://akshitab.github.io/" rel="external nofollow noopener" target="_blank">Akshita Bhagia</a> and <a href="https://www.natolambert.com/" rel="external nofollow noopener" target="_blank">Nathan Lambert</a>, all from the <a href="https://allenai.org/" rel="external nofollow noopener" target="_blank">Allen Institute for AI</a>. I think it would be useful to share some of the main takeaways from the tutorial.</p> <p>The process to build a Large Language Model is very involved, and the authors went through it end to end, providing many details and practical knowledge: starting with the data preparation, continuing wiht model training (also called pre-training), and adaptation (or post-training). Here I summarize the main takeaways from each part, with some additional notes added.</p> <h2 id="data-preparation">Data preparation</h2> <p>Data preparation mainly means data acquisition, data transformation (deduplication, quality control, etc) and data evaluation.</p> <h3 id="data-acquisition">Data acquisition</h3> <p>To acquire data, crawling is common. However, it’s <a href="https://www.dataprovenance.org/Consent_in_Crisis.pdf" rel="external nofollow noopener" target="_blank">becoming harder to crawl data</a>. Many websites are opting out or implementing anti crawlers protection, as shown in the figure below. Note that this will create a barrier to enter for new players. As Kyle Lo said: we are not running out of data, we are running out of <em>open</em> data.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/crawling_data.JPG" sizes="95vw"></source> <img src="/assets/img/blog_images/crawling_data.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Longpre et. al. 2024. Consent in Crisis: The Rapid Decline of the AI Data Commons. Data Provenance Initiative. </div> <p>Crawling data from websites implies, for many of them, understanding the JavaScript logic, which in many cases is unique to the website. This can be challenging because each website may use different frameworks or obfuscation techniques, making it necessary to decipher custom implementations. For example, a site might load data dynamically through complex API calls embedded in asynchronous scripts, requiring tailored solutions for successful extraction. It also requires to parse the data from all the HTML, which is not easy. For PDF’s or scanned documents is also difficult, as many tools are not able to parse the data correctly.</p> <h3 id="data-transformation">Data transformation</h3> <p>That mostly means language filtering, deduplication, removing sensitive content (including private content) and ensuring a desired quality. In reality, it’s a classification problem, and can be done using machine learning with small classifiers. They recommend the library <a href="https://github.com/facebookresearch/fastText" rel="external nofollow noopener" target="_blank">fastText</a>, which is quite efficient (and used across the industry), although more involved classifiers can be used.</p> <p>They also shared the amount of data that remains once the data is filtered for quality and deduplication: reductions are usually of the order of 65 times.</p> <p>Filtering for quality can be, in some cases, problematics, as one can be undesiringly removing specific themes which are usually classified as lower quality, e.g. high school related content.</p> <p>It is also quite difficult to remove personal data, as it was highlighted by <a href="https://aclanthology.org/2023.trustnlp-1.18.pdf" rel="external nofollow noopener" target="_blank">Subramani et al (2023)</a>, where they showed that accuracies with simple Regex or tools like <a href="https://microsoft.github.io/presidio/" rel="external nofollow noopener" target="_blank">Presidio</a> can be quite low.</p> <h3 id="data-evaluation">Data evaluation</h3> <p>Finally, data must be evaluated by training models and running benchmarks, such as MMLU, HumanEval, GSM8K… The evaluation should be done systematically to each group of data, ideally starting with a smaller and cheaper mode. In general it is a very involved process with many nuances, like what is the best model size, measuring the effect of your data filtering, etc</p> <h3 id="a-new-trend-data-curriculum">A new trend: data curriculum</h3> <p>Some interesting new trend: “data curriculum”, which consists of, after training the model with trillions of tokens (high quantity, less quality), at the end of it one switches data to either very high quality sources, specific instructions or synthetic data.</p> <h2 id="model-training-or-pre-training">Model training (or pre-training)</h2> <p>Pre-training, the process where you train a LLM on next token prediction with a large amount of text, is currently mostly done with a Transformer architecture, accepting many different configurations that are successful, including many attention mechanisms (e.g. multi head, grouped-query or multi-query). See image below, how different configurations of the hyperparameters (marked in red) can lead to successful models.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/LLM_hyperparameter_configuration.JPG" sizes="95vw"></source> <img src="/assets/img/blog_images/LLM_hyperparameter_configuration.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Different configurations of the hyperparameters (marked in red) can lead to successful models. From the tutorial authors. </div> <p>In terms of scale the approximate good scaling law given by the <a href="https://arxiv.org/abs/2203.15556" rel="external nofollow noopener" target="_blank">Chinchilla paper</a> (compute budget approximately 6 times the number of parameters by data tokens, and data tokens approx 20 times the number of parameters), although in practice everybody keeps training further.</p> <p>In terms of costs, the pre-training can be very expensive, as it is very intensive in computational resources. See for example the table below, by the authors of the tutorials: a 7b parameter model and 150B tokens (just above the Chinchilla paper budget), will cost approx $10k.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/cost_of_LLM_training.JPG" sizes="95vw"></source> <img src="/assets/img/blog_images/cost_of_LLM_training.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Costs for different models and data sizes. From the tutorial authors. </div> <p>Common positional embeddings today are <a href="https://arxiv.org/abs/2104.09864" rel="external nofollow noopener" target="_blank">rotary positional embeddings</a> (RoPE) and the <a href="https://arxiv.org/abs/2002.05202v1" rel="external nofollow noopener" target="_blank">SwiGLU activation</a>, which, unlike ReLU activation, is smooth (differentiable) at zero.</p> <h3 id="problems-with-loss-function-convergence">Problems with loss function convergence</h3> <p>When the loss function spikes punctually, look at your data, probably is a low quality batch that needs to be filtered.</p> <p>When the loss function starts spiking and diverging, one needs to ensure that the scale of activations and gradients remain roughly the same, and they should scale with model width. Better to use normal initialization and RMSNorm, QK-Norm and change the order of the layer norm. Finally, ensure that the token embedding does not become too small (no weight decay).</p> <p>Run experiments with smaller models first, to find optimal parameters, decide on data ablations.</p> <h3 id="additional-tips-for-pre-training">Additional tips for pre-training</h3> <p>Learning rate annealing also helped. Increase first with the first 10B tokens (to 3e-4) then reduce with cosine decay to 5e-5 for the following trillions of tokens and finally reduce to 0 in the last 50B tokens (e.g. with curriculum training).</p> <p>Use efficient architectures such as Mixture of Experts.</p> <p>In terms of distributing the training across GPU’s, the recommendation is to use FSDP. Here there is an <a href="https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html" rel="external nofollow noopener" target="_blank">excellent tutorial</a>. One needs to ensure that the global batch size is not too large.</p> <p>Use <a href="https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad" rel="external nofollow noopener" target="_blank">flash attention</a> algorithm as is faster and more memory efficient. Try to keep your code simple, before using torch.compile.</p> <p>With large training jobs it’s important to manually do garbage collection at the same time in all processes, as otherwise you can have stalls.</p> <h2 id="adaptation-or-post-training">Adaptation (or post-training)</h2> <p>The output of the pre-training is not ready for use, as it is just predicting the next token. The model needs to be adapted to the specific task at hand: this is the alignment problem: i.e. how we align the model behavior with the human preferences (or the specific task).</p> <p>The first step for adaptation is to have some target tasks (e.g. math, or writting code), with some meaningful evaluation, i.e. some specific benchmarks to evaluate. Then one needs to collect (or build) prompts that represent the task.</p> <p>Currently, in many open source LLMs, different process from <a href="https://openai.com/index/instruction-following/" rel="external nofollow noopener" target="_blank">Reinforcement Learning from Human Feedback</a> (RLHF), created by OpenAI, are used. In reality one can combine them, as we will see below.Some of these methods are:</p> <ul> <li> <a href="https://arxiv.org/abs/2305.18290" rel="external nofollow noopener" target="_blank">Direct Preference Optimization</a> (DPO), much simpler with similar performance. It does not need a reward model (like RLHF), and requires only to optimize a modified version of a simple binary cross entropy objective. It is used in the <a href="https://arxiv.org/pdf/2407.21783" rel="external nofollow noopener" target="_blank">Llama 3 model</a>.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/dpo_summary_from_paper.JPG" sizes="95vw"></source> <img src="/assets/img/blog_images/dpo_summary_from_paper.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> DPO vs RLHF. From [Direct Preference Optimization](https://arxiv.org/abs/2305.18290) paper. </div> <ul> <li> <p><a href="https://huggingface.co/blog/rishiraj/finetune-llms" rel="external nofollow noopener" target="_blank">Supervise Fine Tuning</a> (SFT) is a method that uses a supervised fine-tuning approach, where the model is fine-tuned on a small labeled dataset. It is used in the <a href="https://arxiv.org/pdf/2403.09611" rel="external nofollow noopener" target="_blank">MM1 model</a> from Apple.</p> </li> <li> <p><a href="https://www.interconnects.ai/p/tulu-3" rel="external nofollow noopener" target="_blank">Reinforcement Learning with Verifiable Rewards</a> (RLVR) is a quite simple but effective method coined by the authors, where they replace RLHF by a scoring function that offers positive rewards if the answer is correct. Only applicable (for now) in verifiable rewards, such as math problems with known answers.</p> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_images/RL_with+VR_schema.JPG" sizes="95vw"></source> <img src="/assets/img/blog_images/RL_with+VR_schema.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Reinforcement Learning with Verifiable Rewards. From the tutorial authors. </div> <p>In terms of combining them, the authors of the tutorial suggest to start with SFT (e.g. ~1 million prompts), continue with DPO (another ~1 million prompts), and finally use Reinforcement Learning (~10k-100k prompts).</p> <h3 id="supervised-fine-tuning">Supervised Fine Tuning</h3> <p>With SFT you can get ~80% of performance gain in many tasks.</p> <p>Is used to adapt the pre-trained to specific styles of input, such as chat interactions, and can include system prompts, multi turn dialogues…</p> <p>A lot of data on this category has been created syntehtically by using LLMs to generate variations of human created prompts.</p> <p>Usually one start with mixing the existing datasets, evaluating with benchmarks, and on these benchmarks that are lagging, create new data (they usesd <a href="https://github.com/tencent-ailab/persona-hub" rel="external nofollow noopener" target="_blank">PersonaHub</a>).</p> <h3 id="preference-optimization-dpo">Preference Optimization (DPO)</h3> <p>Aligning to human preferences make the model stronger (e.g. ChatBotArena), allowing to control style.</p> <p>Preference optimization takes a prompt with a chosen and a rejected completion (by a human), and assumes that the probability of the chosen completion should be higher than the rejected one.</p> <p>Surprisingly low learning rates (~5E-7) are standard use. With a 70B parameter model the people from the Allen Institute were able to surpass GPT-4 in various benchmarks.</p> <h3 id="reinforcement-learning">Reinforcement Learning</h3> <p>Although more complex, it allows to normally get ~1% better performance. One can start with synthetic data (LLM-as-a-judge), that has low noise and high bias and then move to human data, with high noise but low bias.</p> <p>The leading synthetic preference data method is <a href="https://arxiv.org/abs/2310.01377v2" rel="external nofollow noopener" target="_blank">UltraFeedback</a>, where instructions are sampled from a large pool of models and GPT-4 is used to annotate preferences.</p> <p>They used the RLVR method, where there is no reward function but just a scoring function that offers positive rewards if the answer is correct. This is for now limited to math and precise instructions.</p> <h2 id="conclusions">Conclusions</h2> <p>The talk reminded me of other recent articles which describe the LLM building process (or at least provide some details), such as the very <a href="https://arxiv.org/pdf/2403.09611" rel="external nofollow noopener" target="_blank">insightful paper from Apple</a> about their MM1 model, or the <a href="https://arxiv.org/pdf/2407.21783" rel="external nofollow noopener" target="_blank">one from Meta on Llama 3.1</a>.</p> <p>The folks from the Allen Institute were very generous in sharing their knowledge, as I think many tips from their practical knowledge may be useful. They also shared <a href="https://github.com/allenai/awesome-open-source-lms" rel="external nofollow noopener" target="_blank">this repository</a> with many open source models and resources.</p> <p>I hope the video is shared soon in <a href="https://neurips.cc/virtual/2024/tutorial/99526" rel="external nofollow noopener" target="_blank">the tutorial page</a>.</p> <p>Edit: <a href="https://www.natolambert.com/" rel="external nofollow noopener" target="_blank">Nathan Lambert</a> tells me that he re-recorded the last part of the tutorial, you can enjoy it here: <a href="https://www.interconnects.ai/p/the-state-of-post-training-2025" rel="external nofollow noopener" target="_blank">The state of post-training in 2025</a>.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'manuelsh/manuelsh.github.io',
        'data-repo-id': 'R_kgDONjpQdw',
        'data-category': 'Comments',
        'data-category-id': 'DIC_kwDONjpQd84Clz9W',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'above',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Manuel Sánchez Hernández. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-C3FNF06T6P"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-C3FNF06T6P');
  </script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>